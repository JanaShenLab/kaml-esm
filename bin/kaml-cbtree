import os
import sys
import io
import numpy as np
import pandas as pd
from pycaret.regression import load_model

import plmpg.cbtrees.features as features

# numeric + categorical columns
num_cols = [
    'com_min_d0_polar', 'com_min_d1_polar', 'com_min_d0_nonpolar',
    'com_min_d1_nonpolar', 'com_min_d0_bb_NH', 'com_min_d1_bb_NH',
    'com_min_d0_neg_O', 'com_min_d1_neg_O', 'com_min_d0_pos_N',
    'com_min_d1_pos_N', 'com_min_d0_hbond_o', 'com_min_d1_hbond_o',
    'com_min_d0_hbond_n', 'com_min_d1_hbond_n', 'com_min_d0_hbond_h',
    'com_min_d1_hbond_h', 'com_min_d0_C_SG', 'com_min_d1_C_SG',
    'com_n_hv_6', 'com_n_hv_9', 'com_n_hv_12', 'com_n_hv_15',
    'com_npolar_5', 'com_npolar_10', 'com_npolar_15',
    'com_polar_5', 'com_polar_10', 'com_polar_15',
    'DA1', 'DA2', 'DD1', 'DD2',
    'flexibility', 'n_sc_C', 'model_pka', 'buried_ratio', 'metal'
]
cat_cols = ['rss', 'rp2ss', 'rp4ss', 'rm2ss', 'rm4ss', 'charge', 'group_code']


def read_pdb(file_path):
    """
    Parses the given PDB file and returns a list of titratable residues
    in the format required by the plmpg.cbtrees.features.generate() function.
    """
    titr_res = {'ASP', 'GLU', 'CYS', 'HIS', 'TYR', 'LYS'}

    orig_resnm = []
    orig_resid = []
    orig_chain = []

    with open(file_path, 'r') as pdbfile:
        for line in pdbfile:
            if not line.startswith("ATOM"):
                continue

            x = line.split()
            # Distinguish chain / resid using logic from original code
            if len(x[4]) > 4:
                next_resid = x[4][:-4]
                chain = x[4][0]
            else:
                next_resid = x[5]
                chain = x[4]

            if not orig_resid or next_resid != orig_resid[-1]:
                orig_resnm.append(x[3])
                orig_resid.append(next_resid)
                orig_chain.append(chain)

    # Build input to `features.generate()`
    residues = [file_path]
    for i in range(len(orig_resnm)):
        if orig_resnm[i] in titr_res:
            residues.append([orig_chain[i], orig_resnm[i], orig_resid[i]])

    return residues


def main():
    pdbfile = sys.argv[1]
    residues = read_pdb(pdbfile)

    print("Calculating features ...")
    # Generate features, but capture them in memory
    feats_str = features.generate(residues)

    # Create DataFrame directly from a string buffer instead of writing to file
    df1 = pd.read_csv(io.StringIO(feats_str))
    df1 = df1[num_cols + cat_cols]

    # Load models
    model_a = load_model("../wts/CBtree/acidic")
    model_b = load_model("../wts/CBtree/basic")

    print("Predicting ...")
    pred_a = model_a.predict(df1)
    pred_b = model_b.predict(df1)

    # Clean up any extraneous local files the library might have generated
    cleanup_files = [
        "error_record_100.txt", "ridainp", "X:A.dat", "rida_results.dat",
        "rida_results.tab", "rida_anchor2.tab", "logs.log"
    ]
    for fn in cleanup_files:
        if os.path.exists(fn):
            os.remove(fn)

    out_fname = f"{os.path.basename(pdbfile).split('.')[0]}_pka.csv"
    with open(out_fname, "w") as out:
        out.write("Residue, pKa\n")
        for k in range(len(residues) - 1):
            if residues[k + 1][1] in ["HIS", "LYS"]:
                out.write(f"{residues[k+1][1]}-{residues[k+1][2]},{round(pred_b[k], 3)}\n")
            else:
                out.write(f"{residues[k+1][1]}-{residues[k+1][2]},{round(pred_a[k], 3)}\n")

    print("Done")


if __name__ == "__main__":
    main()

